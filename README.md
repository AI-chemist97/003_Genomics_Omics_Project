# 2. 췌장암 예측 모델 (GSE16515)

![Python](https://img.shields.io/badge/Python-3.14-blue?logo=python)
![Pandas](https://img.shields.io/badge/Pandas-blue?logo=pandas)
![Scikit-learn](https://img.shields.io/badge/Scikit--learn-F7931E?logo=scikit-learn)
![Seaborn](https://img.shields.io/badge/Seaborn-blue?logo=seaborn)

> 이 프로젝트는 NCBI GEO의 유전체 데이터셋(GSE16515)을 가지고 **췌장암(Cancer)과 정상(Normal) 샘플을 분류**하는 머신러닝 모델을 만들었던 과정을 **기록**한 것입니다.
>
> 단순히 정확도(Accuracy)를 높이는 것이 아니라, 1차 모델의 **치명적인 오류를 '발견'**하고, **'왜' 이 모델이 틀렸는지** 고민하며 **모델을 '개선'**하는 과정에 집중했습니다.

---

## 🔬 분석 과정 및 핵심 로직

### 1. 문제: "이걸 어떻게 읽어야 하지?" (데이터 로드 및 전처리)

처음 데이터를 `pd.read_csv`로 읽었을 때 `ParserError`가 발생했습니다. 파일을 직접 열어보니, `!`로 시작하는 수많은 메타데이터와 실제 유전자 데이터가 섞여 있었습니다.

* **가장 큰 문제:** 샘플 ID(`!Sample_geo_accession`)와 그룹 정보(`!Sample_title`)가 **서로 다른 줄에** 있다는 것이었습니다.
* **해결 과정:**
    1.  이 문제를 풀기 위해, 파일을 한 줄씩 읽어 `!Sample_title`과 `!Sample_geo_accession` 라인을 찾아, 이 둘을 1:1로 짝지어주는 `sample_info` 딕셔너리를 **직접 파싱하여 생성**했습니다.
    2.  `read_csv`의 `skiprows` 옵션으로 실제 데이터 테이블만 불러온 뒤, `.T` (전치)를 사용해 **(행: 샘플, 열: 유전자)** 구조로 변환했습니다.
    3.  `.map(sample_info)`와 `.apply(lambda ...)`를 사용해 최종 `group` 열('cancer' / 'normal')을 추가하여 전처리를 마쳤습니다.

### 2. 탐색: "과연 분류가 가능할까?" (PCA 분석)

데이터에는 5만 개가 넘는 유전자(특징)가 있었기 때문에, 이 '차원의 저주' 문제를 해결하고 그룹 간 경향성을 확인해야 했습니다.

이를 위해, 5만 개의 특징을 2개의 대표 특징으로 압축해 시각화하는 **PCA(주성분 분석)**를 적용해봤습니다.

![PCA Plot](https://i.imgur.com/example.png)  
*(여기에 님의 PCA 그래프 이미지를 넣어주세요)*

* **결과:** PC1 축으로도 암/정상이 어느 정도 나뉘었지만, **더 흥미로운 점을 발견했습니다.** 바로 **PC2 축을 기준으로 -40 이하의 값은 예외 없이 모두 'cancer'**라는 뚜렷한 패턴이었습니다.
* **결론:** 이 그래프를 보고, **"이 데이터는 머신러닝으로 충분히 분류가 가능하겠다"는 확신**을 얻었습니다.

### 3. 1차 모델링: "왜 91%가 '실패'인가?"

PCA에서 얻은 확신을 바탕으로, `RandomForestClassifier` 기본 모델을 훈련했습니다.

* **결과:** `classification_report`는 **정확도 91%**로 꽤 높아 보였습니다.
* **문제 발견:** 하지만 **혼돈 행렬(Confusion Matrix)을 확인해보니, 치명적인 문제를 발견했습니다.**

![1차 혼돈 행렬 이미지](https://i.imgur.com/example_cm1.png)  
*(여기에 1차 혼돈 행렬 그래프 이미지를 넣어주세요)*

> **실제 암 환자 1명(FN=1)을 정상으로 잘못 예측**한 것입니다.
> 의료 진단에서 이 실수는 91%의 정확도보다 훨씬 심각한, **'0점짜리 결과'**라고 **판단**했습니다.

### 4. 모델 개선: "어떻게 실수를 바로잡을까?"

1차 모델의 실패를 바탕으로, 2차 모델의 목표를 "정확도"가 아닌 **"암 환자를 놓치지 않는 것(재현율 100%)"**으로 다시 잡았습니다.

* **탐색:** "모델이 이 실수를 더 심각하게 받아들이도록(벌점을 주도록) 만들 방법"을 **탐색**했습니다.
* **발견:** `scikit-learn`의 **공식 문서**와 AI(Gemini)의 도움을 통해 `RandomForestClassifier`의 **`class_weight`** 파라미터가 이 역할을 한다는 것을 **알게 되었습니다.**
* **전략 수립:**
    * `class_weight='balanced'` 옵션은 데이터 비율에 따라 '소수' 그룹에 가중치를 줍니다.
    * 하지만 제 데이터는 'cancer'가 다수 그룹일 수 있으므로, 이 옵션은 오히려 FN을 악화시킬 수 있다고 판단했습니다.
    * 따라서 "데이터 비율과 상관없이 'cancer' 클래스를 틀렸을 때 10배의 벌점을 주겠다"는 의미로 **`class_weight={'cancer': 10, 'normal': 1}`**을 **수동으로 설정**하는 것이 제 목표에 더 확실하다고 **결정**했습니다.

---

## 💡 5. 최종 결론

### 재현율(Recall) 100% 달성
`class_weight`를 적용한 2차 모델(`model_tuned`)을 훈련한 결과, **정확도 100%, 재현율 100%**를 달성했습니다.

![2차 혼돈 행렬 이미지](https://i.imgur.com/example_cm2.png)  
*(여기에 2차 혼돈 행렬 그래프 이미지를 넣어주세요)*

혼돈 행렬에서 **FN(False Negative)이 0**이 된 것을 확인하며, '암 환자를 놓치는 실수'를 완벽히 제거한 '안전한' 모델을 완성했습니다.

### 예측의 근거: 핵심 유전자 도출
마지막으로, 이 똑똑해진 모델이 **'무엇을 보고'** 판단했는지 `feature_importances_`를 확인해봤습니다.

![특성 중요도 그래프](https://i.imgur.com/example_fi.png)  
*(여기에 특성 중요도 그래프 이미지를 넣어주세요)*

* **결론:** `228507_at`, `209950_s_at`, `235651_at` 등이 췌장암을 구분하는 가장 핵심적인 생물학적 마커일 가능성이 높다는 구체적인 결론을 **도출**했습니다.
